{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“This script demonstrates the following steps: 1. Load the ImageNet dataset using TensorFlow Datasets (TFDS). 2. Save images locally as JPEG files. 3. Reload the saved images and use them to create a dataset for training. 4. Define a simple CNN model using Flax. 5. Train the model on the dataset.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hildafs/projects/phy230056p/junzhez/AI/maskgit/gmmg\n",
      "\u001b[0m\u001b[38;5;33mconfig\u001b[0m/       nets.ipynb  test1.ipynb        train_token.ipynb\n",
      "layers.ipynb  \u001b[38;5;33msrc\u001b[0m/        tf_datasets.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%cd /hildafs/projects/phy230056p/junzhez/AI/maskgit/gmmg\n",
    "%ls\n",
    "\n",
    "# Directory to save images\n",
    "data_dir = '/hildafs/projects/phy230056p/junzhez/data/'\n",
    "# data_name = 'imagenet2012_tfds'\n",
    "data_name = 'mnist'\n",
    "save_dir = os.path.join(data_dir, data_name)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ImageNet dataset\n",
    "dataset_name = 'mnist'\n",
    "split = 'train[:80%]'  # Using a small subset for demonstration purposes\n",
    "dataset, info = tfds.load(dataset_name, data_dir=save_dir, split=split, with_info=True)\n",
    "\n",
    "# Preprocess dataset\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = sample['label']\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(preprocess)\n",
    "\n",
    "# Convert to numpy arrays and batch the data\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:49:58.234772: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:49:58.825803: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:49:59.398702: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:00.050146: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:00.644332: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:01.244848: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:01.818696: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:02.391407: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:02.993996: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed\n",
      "Epoch 10 completed\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:50:03.627403: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "class CNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "def create_train_state(rng, learning_rate):\n",
    "    cnn = CNN()\n",
    "    # batch_size, height, width, channels\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)\n",
    "\n",
    "# Training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = CNN().apply({'params': params}, batch['image'])\n",
    "        one_hot = jax.nn.one_hot(batch['label'], 10)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits, one_hot))\n",
    "        return loss\n",
    "    \n",
    "    grads = jax.grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state\n",
    "\n",
    "# Train the model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = create_train_state(rng, learning_rate=0.01)\n",
    "\n",
    "for epoch in range(10):  # Train for 10 epochs\n",
    "    for batch in dataset.as_numpy_iterator():\n",
    "        images, labels = batch\n",
    "        batch = {'image': images, 'label': labels}\n",
    "        state = train_step(state, batch)\n",
    "    print(f'Epoch {epoch+1} completed')\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and Visualize\n",
    "\n",
    "We now also add in train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset using TensorFlow Datasets\n",
    "dataset_name = 'mnist'\n",
    "train_split = 'train[:80%]'\n",
    "val_split = 'train[80%:]'\n",
    "test_split = 'test'\n",
    "\n",
    "train_dataset, train_info = tfds.load(dataset_name, data_dir=save_dir, split=train_split, with_info=True)\n",
    "val_dataset = tfds.load(dataset_name, data_dir=save_dir, split=val_split)\n",
    "test_dataset = tfds.load(dataset_name, data_dir=save_dir, split=test_split)\n",
    "\n",
    "# Preprocess dataset\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = sample['label']\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "val_dataset = val_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "# Convert to numpy arrays and batch the data\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "def create_train_state(rng, learning_rate):\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)\n",
    "\n",
    "# Training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = CNN().apply({'params': params}, batch['image'])\n",
    "        one_hot = jax.nn.one_hot(batch['label'], 10)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits, one_hot))\n",
    "        accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['label'])\n",
    "        return loss, accuracy\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, accuracy), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(state, batch):\n",
    "    logits = state.apply_fn({'params': state.params}, batch['image'])\n",
    "    one_hot = jax.nn.one_hot(batch['label'], 10)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits, one_hot))\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['label'])\n",
    "    return loss, accuracy\n",
    "\n",
    "def evaluate_model(state, dataset):\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in dataset.as_numpy_iterator():\n",
    "        images, labels = batch\n",
    "        batch = {'image': images, 'label': labels}\n",
    "        loss, accuracy = compute_metrics(state, batch)\n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "    \n",
    "    total_loss /= num_batches\n",
    "    total_accuracy /= num_batches\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:38.501971: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-05-29 00:52:40.025165: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:40.644606: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6225, Train Accuracy: 0.8259, Val Loss: 0.2952, Val Accuracy: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:41.542080: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:41.760854: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2459, Train Accuracy: 0.9251, Val Loss: 0.2105, Val Accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:42.670735: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:42.864124: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.1822, Train Accuracy: 0.9446, Val Loss: 0.1650, Val Accuracy: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:43.748056: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:43.934597: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1468, Train Accuracy: 0.9558, Val Loss: 0.1389, Val Accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:44.872181: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:45.065218: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1236, Train Accuracy: 0.9635, Val Loss: 0.1204, Val Accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:45.967176: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:46.164549: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1072, Train Accuracy: 0.9681, Val Loss: 0.1092, Val Accuracy: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:47.096955: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:47.287667: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0951, Train Accuracy: 0.9715, Val Loss: 0.1008, Val Accuracy: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:48.183617: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:48.375708: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0854, Train Accuracy: 0.9744, Val Loss: 0.0936, Val Accuracy: 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:49.317335: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:49.505696: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0776, Train Accuracy: 0.9765, Val Loss: 0.0892, Val Accuracy: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:50.410163: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-29 00:52:50.602780: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0710, Train Accuracy: 0.9788, Val Loss: 0.0854, Val Accuracy: 0.9743\n",
      "Test Loss: 0.0764, Test Accuracy: 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:52:51.213063: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = create_train_state(rng, learning_rate=0.01)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    train_iter = iter(train_dataset.as_numpy_iterator())\n",
    "    while True:\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        images, labels = batch\n",
    "        batch = {\"image\": images, \"label\": labels}\n",
    "        state, loss, accuracy = train_step(state, batch)\n",
    "        epoch_loss += loss\n",
    "        epoch_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "\n",
    "    epoch_loss /= num_batches\n",
    "    epoch_accuracy /= num_batches\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_accuracy = evaluate_model(state, val_dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = evaluate_model(state, test_dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 28, 28, 1)\n",
      "(10, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAADwCAYAAABBoq7TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs/0lEQVR4nO3daXiV1dn28WtnIANDAgSZIiQECDIELGABhRiVCDJKRUWlTKIiyKAtiJaoQMkDikhVpBaZBB7BgkyC4gBJZWjLECpBKlNKIYCAzBggYb0f+sLTSNbKzp2s5N7J/3ccfGCf+173ynCGcLHJ8iillAAAAAAAAABFzK+kNwAAAAAAAIDSicETAAAAAAAArGDwBAAAAAAAACsYPAEAAAAAAMAKBk8AAAAAAACwgsETAAAAAAAArGDwBAAAAAAAACsYPAEAAAAAAMAKBk8AAAAAAACwotgGTx6Px6tfGzZsKK4tFci5c+fk5ZdfloYNG0poaKjUrl1bevfuLenp6Y7XvPvuu3O97SEhIdK8eXN566235Nq1a0W4+7xt2LDhpvd5//79JSoqqsBrzZgxQ+bOnVtke/tvHo9HXn31VcfX79ixQ3r27Cm1atWS0NBQadSokYwfP14uXbpUdJssA3y9w1FRUXnu95lnnnG8Jh32TmE6fP1tzOvXli1binajpRj9vRn99Q79dQc6fDM67B06XPJ8vb8iIidPnpQRI0ZIVFSUBAUFSfXq1aVz587y448/OlqP/nqnsH8PFhH55ptv5IEHHpDKlStLSEiINGjQQCZMmFA0GyyAgOK60ebNm3P9fsKECbJ+/Xr5+uuvcz3euHHj4tpSgXTr1k22bt0qr776qrRq1UoOHz4s48ePl7Zt28q3334rdevWdbRuvXr1ZOHChSIi8sMPP8jMmTNl1KhRcvToUZk8eXJRvgleGTdunIwYMaLA182YMUMiIiKkf//+Rb+pQti9e7e0a9dOYmNj5a233pKIiAhJTU2V8ePHy7Zt22TFihUlvUWf4esdFhG588475Y033sj1WPXq1Qu1Jh0uHpMmTZKEhIRcjzVt2rSEduN76G/e6G/xoL+FR4fzRoeLBx0uHF/vb2ZmprRv314CAgJk3Lhx0qBBAzl58qSsX79erly54nhd+mvfokWLpG/fvvLwww/L/PnzpUKFCrJ//37JzMws9r0U2+CpTZs2uX5frVo18fPzu+nxn7t06ZKEhoba3Fq+9u3bJ6mpqfK73/1Ofvvb3954vH79+tKuXTtZtmyZjBo1ytHaISEhud4HnTt3lkaNGsk777wjEydOlMDAwJuuUUpJVlaWhISEOLqnSUxMTJGvWZIWLVokWVlZsnTp0htv2z333CNHjx6V999/X06fPi2VK1cu4V36Bl/u8HXh4eH57reg6HDxaNCgQZF/7MoS+ps3+ls86G/h0eG80eHiQYcLx9f7++yzz8rly5dl69atuf7e1KtXr0KtS3/tOnLkiDz11FPy9NNPy4wZM248/vMhcnFx1c94uvvuu6Vp06aSmpoq7dq1k9DQUBk4cKCI6F9mFhUVddN08dixY/L0009LZGSklCtXTqKjo+W1116T7OxsR/u6/kkfFhaW6/Hw8HAREQkODna0ru5eLVu2lEuXLsmJEydE5D9v+7Bhw2TmzJly2223SVBQkMybN09ERPbu3SuPPfaY3HLLLRIUFCS33XabvPvuuzetu2fPHunUqZOEhoZKRESEPPPMM3L+/PmbnpfXSwyvXbsmb7/9trRo0UJCQkJufOOwcuVKEfnPxyA9PV1SUlJuvFzyv9c4d+6c/OY3v5Ho6GgpV66c1K5dW0aOHCkXL17MdZ9z587J4MGDpWrVqlKhQgXp1KmTfP/994V5dxo/dn5+flKuXLlCrY/c3Nrh4kSHi7bDKD70l/7SX99Gh+kwHfZdbu1vRkaGrFy5UgYPHmz9H+vpb9H2d9asWXLx4kUZM2ZModYpKsX2iidvHT16VJ544gkZPXq0TJo0Sfz8CjYbO3bsmNxxxx3i5+cnSUlJEhMTI5s3b5aJEydKRkaGzJkz58Zz+/fvL/PmzZODBw8a/z9n3bp1pUePHjJt2jRp2bKltG7dWg4fPizDhw+XOnXqyKOPPur0zc3T/v37JSAgIFe5ly9fLn/5y18kKSlJatSoIbfccsuN/0ZWp04dmTp1qtSoUUM+//xzGT58uJw8eVJeeeUVERE5fvy4xMfHS2BgoMyYMUOqV68uCxculGHDhnm1n/79+8uCBQtk0KBBMn78eClXrpxs375dMjIyRETkk08+kYceekjCwsJuTFODgoJE5D+T+vj4eDl8+LC89NJLEhcXJ+np6ZKUlCTffvutfPnll+LxeEQpJT179pRNmzZJUlKStG7dWjZu3CidO3fOc08ej0fi4+Pz/b/Q/fr1k7feekuGDBkikydPlmrVqklKSor88Y9/lKFDh0r58uW9eh/Ae27s8HWpqalSsWJFycrKkgYNGsigQYNk5MiR4u/vX9A304gOF12Hrxs6dKg8+uijEhoaKm3btpVx48bJXXfd5dW18B79pb/017fRYTpMh32XG/v7l7/8RZRSUqtWLenTp4+sWrVKsrOzpU2bNpKcnCxt27Z1+ubmif4WXX9TU1OlSpUqsmfPHunRo4fs2rVLqlSpIr169ZIpU6ZIpUqVvHofFBlVQvr166fKly+f67H4+HglIuqrr7666fkiol555ZWbHq9bt67q16/fjd8//fTTqkKFCupf//pXrue98cYbSkRUenr6jccGDhyo/P39VUZGRr77vXLliho8eLASkRu/4uLi1MGDB/O9Vic+Pl41adJEXb16VV29elVlZmaqF198UYmI6t27943niYgKCwtTP/74Y67r77//fhUZGanOnj2b6/Fhw4ap4ODgG88fM2aM8ng8Ki0tLdfzOnbsqERErV+//sZj/fr1U3Xr1r3x+9TUVCUi6uWXXza+LU2aNFHx8fE3PZ6cnKz8/PzU3//+91yP//nPf1YiotasWaOUUmrt2rVKRNT06dNzPe/3v/99nh97f39/dc899xj3dN13332nGjVqlOtjN3z4cHXt2jWvrkfefK3Dzz77rJo9e7ZKSUlRy5cvV48//rgSEfXEE0/ke60OHbbf4e3bt6sRI0aoTz75RKWmpqrZs2er2267Tfn7+6vPPvss3+uRN/pLf+mvb6PDdJgO+y5f6m9ycrISEVWpUiXVo0cP9dlnn6mlS5equLg4FRwcrHbu3OnFW3wz+mu/v7GxsSo4OFhVrFhRTZo0Sa1fv15NmTJFhYSEqDvvvLPY/y7susFT5cqV83y+t4WrXbu26tat241P4uu/0tPTlYioGTNmONrvoEGDVJUqVdS0adNUSkqKWrx4sWrVqpWKjo726g/cvFz/AvPfvwIDA9Xjjz+uzpw5c+N5IqIefPDBXNf+9NNPKiAgQD333HM3va1r1qzJ9cl8xx13qKZNm950/zlz5uRbuLFjxyoRUZmZmca3RVe4O++8U8XFxd20x/PnzyuPx6NGjx6tlFJq9OjRSkTUyZMnc11/8OBB7cfeGwcPHlT169dXd955p/rzn/+sUlJS1JQpU1SlSpXUwIEDHa2J//C1Dudl2LBhSkTU9u3bHV1Ph+13OC+nT59WkZGRKi4ursjWLGvoL/2lv76NDtNhOuy7fKm/14cfjRs3VtnZ2Tcez8zMVKGhoerxxx8v8JpK0d/i6G+DBg2UiKjk5ORcj7/11ltKRNQXX3zhaF2nXPdf7WrWrFmo648fPy6rVq3K84eRifznKMiC+uyzz+SDDz6Qjz/+WB566KEbjycmJkpUVJS8+uqruV66WBAxMTHy0UcficfjkeDgYImOjs7zh8j9/P1y6tQpyc7OlrffflvefvvtPNe+/raeOnVKoqOjb8pr1KiR7/5OnDgh/v7+Xj03L8ePH5d9+/bl+/E4deqUBAQESNWqVQu8R5MXX3xRzp07J2lpaTf+W12HDh0kIiJCBg4cKL/+9a8lPj6+UPdAbm7ssM4TTzwh77zzjmzZskVuv/12R2vQYbsdzkt4eLh07dpVZs6cKT/99JOVHzBZVtFf+lvQPRYU/bWLDtPhgu6xoOiwPW7s7/XPqfvuuy/Xf4utWbOmNG/eXLZv3+5ss0J/bfe3atWqsnfvXrn//vtzPd65c2cZOXKkbN++Xe67775C3aMgXDd48ng8eT4eFBQkly9fvunxU6dO5fp9RESExMXFye9///s816lVq1aB95SWliYiIq1bt871eHh4uNSvX1927dpV4DWvCw4OllatWuX7vJ+/XypXriz+/v7St29fGTp0aJ7XXC9Z1apV5dixYzfleT32c9WqVZOcnBw5duyYoy+GEREREhISIrNnz9bm1/eYnZ0tp06dylU6b/ZokpaWJo0bN77pZzld/1ju2rWLwVMRc2OHdZRSIiIF/j/0/40O2+2wzvWPne7zDc7Q37zR36JFf+2hw3mjw0WLDtvhxv7GxcVpM6UU/TUo6f7GxcXJli1bbnq8KL72OuG6wZNOVFSU/OMf/8j12Ndffy0XLlzI9VjXrl1lzZo1EhMTU2Q/ef96Sbds2SJ169a98fipU6fk+++/l3vvvbdI7lMQoaGhkpCQIDt27JC4uDjj6WwJCQkyZcoU2blzpzRv3vzG44sWLcr3Pp07d5bk5GR57733ZPz48drnBQUFyU8//XTT4127dpVJkyZJ1apV85w2/3yPCxculOHDhxdojya1atWSXbt2yYULF6RChQo3Ht+8ebOIiERGRhZqfXivJDusM3/+fBG5+Zjb4kCHnTt9+rSsXr1aWrRoUaSnikKP/uZGf52jvyWDDudGh52jw8WvJPv7y1/+UiIjI2XdunWSk5Nz41VPmZmZsnPnTnnssceK5D4FQX+986tf/Uref/99Wbt2ba5Xla5Zs0ZEiv9rr88Mnvr27Svjxo2TpKQkiY+Pl927d8s777wjYWFhuZ43fvx4+eKLL6Rdu3YyfPhwiY2NlaysLMnIyJA1a9bIzJkzbwwbBg0aJPPmzZP9+/fnGij9XK9evSQpKUmGDBkihw8fll/84hdy9OhRef311+XSpUsyYsSIXM8v6EkRTk2fPl3uuusuad++vQwZMkSioqLk/Pnzsm/fPlm1apV8/fXXIiIycuRImT17tnTp0kUmTpx446f579mzJ997tG/fXvr27SsTJ06U48ePS9euXSUoKEh27NghoaGh8txzz4mISLNmzeSjjz6SxYsXS7169SQ4OFiaNWsmI0eOlKVLl0qHDh1k1KhREhcXJ9euXZNDhw7JunXr5IUXXpBf/vKXkpiYKB06dJDRo0fLxYsXpVWrVrJx40b58MMP89xXQECAxMfHy1dffWXc/8iRI6Vnz57SsWNHGTVqlERERMiWLVskOTlZGjdurD0tAEWvJDu8aNEiWbZsmXTp0kXq1q0rZ86ckY8//lg++ugj6d+/f64/iETosJs6/Nhjj0mdOnWkVatWEhERIXv37pWpU6fK8ePHZe7cuQV7h8Mx+nsz+kt/fQkdvhkdpsO+oiT76+fnJ9OmTZOHH35YevToIUOGDJGLFy/KhAkTpFy5cjJ27Nhcz6e/7ulvYmKidOvWTcaPHy/Xrl2TNm3ayNatW+W1116Trl27Fv/JlMX6E6X+i+6HqjVp0iTP51++fFmNHj1a3XrrrSokJETFx8ertLS0m36omlJKnThxQg0fPlxFR0erwMBAVaVKFdWyZUv18ssvqwsXLuTag4h4dTLd0aNH1bBhw1T9+vVVcHCwqlWrlurSpYvavHlzruedP39eiYh69NFH813T9Pb+NxFRQ4cOzTM7ePCgGjhwoKpdu7YKDAxU1apVU+3atVMTJ07M9bzdu3erjh07quDgYFWlShU1aNAgtWLFinx/qJpSSuXk5Khp06appk2bqnLlyqmwsDDVtm1btWrVqhvPycjIUImJiapixYpKRHKtceHCBfW73/1OxcbG3ri+WbNmatSoUerYsWM3nnfmzBk1cOBAFR4erkJDQ1XHjh3Vnj178vyhaiKS5w9xy8vXX3+tEhMTVY0aNVRISIhq2LCheuGFF276AW4oGF/q8ObNm9W9996ratSooQIDA1VoaKhq3bq1mjFjhsrJycn1XDrsrg4nJyerFi1aqLCwMOXv76+qVaumHnzwQfW3v/0t32uhR3/pL/31bXSYDtNh3+VL/b1u+fLlqnXr1io4OFiFhYWp7t275zolTyn667b+KqXUpUuX1JgxY9Stt96qAgICVJ06ddTYsWNVVlaWV9cXJY9S//8/+aFIrFmzRrp27So7d+6UZs2alfR2ABQQHQZ8F/0FfBsdBnwX/YVJ8f5EqTJg/fr18uijj1I2wEfRYcB30V/At9FhwHfRX5jwiicAAAAAAABYwSueAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYEWAt0/0eDw29wH4PLcfEEmHATM3d5j+AmZu7q8IHQby4+YO01/AzJv+8oonAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWOH1qXYAAAAAAAC+KCBAP/74/PPPtdnGjRu1WVJSUqH2VFbwiicAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVujPEwQAAAAAACgFJk+erM0SEhK02TfffGNjO2UKr3gCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFgRUNIbAAAAAAAAKKyEhARt9uSTT2qz9PR0bbZ27dpC7Qm84gkAAAAAAACWMHgCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFR6llPLqiR6P7b0APs3LKpUYOgyYubnD9Bcwc3N/RehwYURERGizwYMHW7nn5s2btdmGDRuK/H79+/c35jVr1tRmjz32mDZr3LixNhs+fLg2e/fdd437scHNHaa/7lKxYkVjfuTIEW1Wvnx5bfbggw9qs5UrV+a/sTLMm/7yiicAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVgSU9AZQ/Fq1aqXNOnbsWIw7+Y+lS5dqs++//74YdwKUXU2bNjXm1atX12am46xDQkK02YEDB7TZe++9p834ugAAvmfs2LHabMyYMdrMz0//7+ShoaGF2pPO1atXtdnly5e12eTJk7XZwIEDtVmdOnWM+/H399dmp0+f1maTJk3SZn/605+M9wRKUlhYmDZbtmyZ8doKFSpos2nTpmmzlStX5r8xOMYrngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABY4VFKKa+e6PHY3kuZZDrusX///tosMTHRuO7dd9+tzQICArRZUFCQcV0bsrKytFl2drY2Mx1n27lzZ222bds27zZWQF5WqcTQ4dLD1H/T5/69996rzSIjI433NB1ra8NXX32lzfL7+ueUmztMf51r1KiRNuvRo4ejNaOjo435gAEDHK3rS3JycrTZa6+9ps1Mx80Xhpv7K1I2Ojx27FhjnpSUpM0CAwMd3fObb77RZgcOHNBmX3zxhXHdBQsWaDOnn2uHDh3SZhs2bDBeO3v2bG32/fffa7Mffvgh3325hZs7XBb66zajRo3SZlOnTjVem56ers0SEhK02cmTJ/PfGPLkTX95xRMAAAAAAACsYPAEAAAAAAAAKxg8AQAAAAAAwAoGTwAAAAAAALCCwRMAAAAAAACsYPAEAAAAAAAAKzzKy7MrOUbSLCIiQps98MAD2uyRRx7RZp06dXK8H9PHy+lxpStWrNBmZ8+edbRmfkJDQ7XZQw89pM3Onz+vzcLDwwuzJS03HwMrQocLw/S+u+2227TZ0qVLtVlkZKTj/QQFBWkzf39/x+uaXL58WZvZ6r9OzZo1razr5g7TX7Pp06drs6eeekqbmboEkZSUFG2Wlpamzb766itttnr16sJsScvN/RUpPR3u2bOnNlu0aJHx2nLlymmzN954Q5vNmTNHmx07dkybFebPJtN+unfvrs3mzZunzebOnavNjhw54tW+SjM3d7i09NdtoqKitNm+ffu02f79+43rJiQkaLPMzMx894WC86a/vOIJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUBJb0BX/Lkk09qs5deekmb1a1bt8j3snv3bmO+d+9ebbZ582ZttnLlSm128OBBbXblyhXjfpwyHWebnZ2tzcaMGWNjOyijYmJitNm3335r5Z6mTm3dutXRmps2bXK8ZkZGhjbbsmWLo/0ABZGenq7NYmNjtZmfn/7f2Eyf12+//bY2mz9/vjYrjPvuu0+bffnll1buaXLx4kVtlpWVVYw7gVtUqlRJm5UrV87xuh06dNBmL774ouN1nZo6dao2M31t+Ne//mVjO4DPCgoK0mb/+7//q82uXr2qzZKSkoz3zMzMzH9jKHa84gkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYIVHKaW8eqLHY3svJe7JJ5805m+++aY2K1++vKN77t69W5tlZGRos6eeesq47tGjRx3tx23q1aunzcLDw7XZ9u3bLezGzMsqlZiy0OHCSExM1GZ/+tOftFlkZKSN7Rj7HxMTY+WeZZ2bO1wW+tuvXz9j/sEHH2gzPz/9v6ONHz9em/3hD3/QZj/++KNxP3AXN/dXpPR0uGbNmtpsyZIlxmvbtm2rzc6dO6fNhgwZos0WL15svCd8h5s7XFr6WxJGjx6tzf7nf/5Hm5m63adPn0LtCUXPm/7yiicAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVgSU9Abc5Pnnnzfm5cuX12YXL17UZi+99JI2W7p0qTY7evSocT9u0qRJE2PeqFEjbfbMM88U9XZk3bp12uz1118v8vvBN5iOZE5OTtZmFStW1GaHDh3SZr/61a+0WUREhDYTEdm2bZsxB0ob01HrIiJ+fs7+rWz37t3a7Mcff3S0JlBWmb43feSRR4zXmo5HN/V/5syZ2uzatWva7OOPPzbuB0DRmDZtmjYbPny4NtuyZYs269u3b6H2BPfhFU8AAAAAAACwgsETAAAAAAAArGDwBAAAAAAAACsYPAEAAAAAAMAKBk8AAAAAAACwgsETAAAAAAAArPAopZRXT/R4bO+lxJmOXBYRiY2N1WbffvutNuvVq5c2O3DgQP4bc8B0VLspu/3227VZ7969tVl8fLxxP+Hh4cZcJzs7W5vt27fP0ZpNmjRxdF1+vKxSiSkLHe7QoYMx/+CDD7RZvXr1tNmmTZu0WY8ePbQZR7X7Fjd3uLT0t2HDhtps69atxmsrVKjg6J4XLlzQZpmZmY7WnDVrljGfP3++Nvvhhx8c3RNmbu6vSOnpcGHUrFlTmy1ZskSbtW3bVptdunRJm/Xr10+bffLJJ9oMJcPNHaa/IrVr19Zmpr9DX716VZt16dJFm/31r3/1bmPFxPQ5EBgYaLw2JyfHUeZLvOkvr3gCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYIVHeXl2ZVk4RtJ0FKSISGxsrKN1z549q81WrVrlaM38NGvWTJs1b97cyj1tmD17tjYbPHhwMe4kf24+BlakbHS4evXqxtzp0ekme/bs0WZHjx7VZmlpacZ1P/vsM2325Zdf5rsvFJybO1xa+jtz5kxt9tRTTxXjTuw6ePCgNnvvvfe02YIFC7TZsWPHCrWn0s7N/RUpPR22xfTn9/Lly7VZ69attdmVK1e02SOPPGLcj63vz6Hn5g7TX5GUlBRt1r59e23Wt29fbbZw4cJC7cmJli1barMGDRposwcffFCb9e7d23hP0/f0DzzwgPFaX+FNf3nFEwAAAAAAAKxg8AQAAAAAAAArGDwBAAAAAADACgZPAAAAAAAAsILBEwAAAAAAAKxg8AQAAAAAAAArPMrLsyvLwjGSffr0MeavvPKKNjMdv1gSTB8vNx9X+nNHjhzRZnXq1CnGneTP7e/XstBhf39/Yz5u3DhHWUnIycnRZv/+978drWk60nbTpk2O1ixN3Nzh0tLfKVOmaLPf/OY3Vu557NgxbZaWluZozTZt2hjz8PBwR+tu3LhRm5mOaza9jWWFm/srUno6XBKqVq2qzUzHlN9+++2O79mlSxdt9vnnnzteF3pu7nBZ6G9iYqIx//TTT7XZd999p83uuOMObZaVlaXNTN/T9+/fX5uJmL+fiI6O1mblypUzruvU/v37tZnbZghOedNfXvEEAAAAAAAAKxg8AQAAAAAAwAoGTwAAAAAAALCCwRMAAAAAAACsYPAEAAAAAAAAKxg8AQAAAAAAwAqP8vLsyrJwjGR+oqKitNkLL7ygzZ599lkLuzEzfbxMH/JJkyZps4sXLzrez8CBA7VZTEyMNjty5Ig2q1OnjuP92ODmY2BF6HB+YmNjtVmnTp2K/H4tWrQw5vfdd582q127dhHvRmTFihXGfMiQIdqstBzl7uYOl5b+1qpVS5v98Y9/NF4bGhqqzd58801ttm/fPm32z3/+03hPnR49ehjzcePGabNf/OIXju65ceNGbda7d2/jtaWloyZu7q9I6emw2wwYMECbzZo1y/G6fn76f5vv1q2bNlu9erXje5Z1bu5waelvpUqVtFl6errxWtP3nqbvk9etW5f/xvLQvXt3bbZ8+XJHa+Zn586d2sz094Tg4GDjuvv379dmDRo0yH9jPsCb/vKKJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFR6llPLqiR6P7b24XlRUlDb78ssvtVlMTIw2M737r1y5os06deqkzURENmzYYMydiI2N1Wamt19EpHbt2trs1KlT2qxjx47aLC0tzXjP4uZllUoMHfYt5cuX12b33HOPNmvatKk2Gz9+vDY7d+6ccT/PPvusNlu8eLHxWl/h5g7TX98SFhamzdatW6fNWrdu7eh+ffv2NeYLFy50tK4vcXN/ReiwLX5++n9D//Wvf63NZs2aZVzX9PEyfX9er149bXb06FHjPcs6N3e4tPR3zJgx2iw5Odl47b59+7RZXFycNsvKytJmzZs312apqanaLL+Px7Rp07TZxx9/rM0OHDigzbp3767NFi1aZNzP/v37tVmDBg2M1/oKb/rLK54AAAAAAABgBYMnAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWBFQ0htwk5iYGGM+YsQIbRYdHa3Nrl27ps2WLVumzQYMGKDNLly4oM0K4w9/+IM2GzRokDYLDg42rrt161ZtlpCQoM0uXrxoXBe+q2nTptps165dxbgTdzJ97q9atcpR9sADD2izdu3aGfcTHh5uzAH8n7Nnz2qzSZMmabO5c+dqs7CwMG1Wu3Ztr/YFlDam77Hnz5+vzfI7jn3o0KHarEWLFtrs/fff12ZTp07VZhs2bDDuB/BWtWrVtNnIkSMdrzthwgRtlpWVpc0qVqyozaZMmaLNTN3u2bOnNhMRSUlJMeZOZGRkFPmaZQ2veAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABgRUBJb6C4xcTEaLPVq1cbr23YsKGjey5ZskSbDRo0SJtdunTJ0f1EzEfVr1ixQpvVqVNHm/n56eeUa9asMe5n4sSJ2sx0bDxKr1mzZmmzEydOaLNu3brZ2E6p0aFDB20WGBiozf79738b1z18+LDjPQH4P6Y/g1NTU7WZ6WvfM888Y7yn6chqoLQyHcc+Z84c47Xnzp3TZgsXLtRmnTt31mZVqlTRZqNHjzbuZ+PGjcYcuM70d8AaNWpoM6WUcV1/f39H6yYmJmqzjh07arPnn39em+3YsUObiYiEhIRos+joaG02duxYbdarVy9tlt/fZYcNG2bMywpe8QQAAAAAAAArGDwBAAAAAADACgZPAAAAAAAAsILBEwAAAAAAAKxg8AQAAAAAAAArGDwBAAAAAADACo/K7+zE60/0eGzvpcjExMRos9WrV2uzhg0bOr7nRx99pM1MxxxnZ2drsx49emizpKQk434iIiK0WdWqVbXZoUOHtNmHH36ozZKTk437+emnn4x5aeBllUqM2zq8Zs0abdaiRQtt9u6772qzuXPnGu955MiR/LblE8LCwrTZtm3btJnpCFnTEe8i5mNkSws3d9ht/W3UqJE2++c//6nN3Pw+Li7169fXZikpKdqsZs2a2iwjI8N4z3r16uW7L1/n9s8tt3XYhjZt2hjzW2+9VZtt375dm+3fv9/xnmwYOnSoNpsyZYo2CwoK0mbnzp0z3tN0JP3WrVuN1/oKN3fYl/pbuXJlbbZ8+XJt1r59e8f3PHHihDa7fPmyNouMjNRme/fu1Wb5fa5cvHhRm91+++3Ga3V27dqlzebMmWO8dtq0aY7u6Uu86S+veAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABghUd5eXalLx0j+eabb2qzESNGOF7373//uzYzHXNqOsJ8+PDh2qx///5e7Ssvpo/X+vXrtdnzzz+vzXbu3Ol4P2WBm4+BFXFfh+Pi4rTZp59+qs1q1aqlzQ4fPmy85+zZs7XZF198oc02bdpkXNeGhIQEbfbOO+9oM9Mx96Yjbe+55x7jfrZs2WLMSwM3d9ht/T19+rQ2W7t2rTZ77bXXtJnp81PE3O/s7GzjtW4yefJkbfbb3/7W0Zqvv/66MR8zZoyjdX2Jm/sr4r4OOzVgwABtNn36dOO1mzdv1mb333+/4z25yXPPPafNJk2apM1CQkKM665atUqbDRw4UJuZvla7jZs7XFr6e9ddd2mzDz/80Hht3bp1i3o7JeLkyZPabMGCBdpsyZIl2qwsfI+cH2/6yyueAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWMHgCAAAAAACAFQyeAAAAAAAAYAWDJwAAAAAAAFjB4AkAAAAAAABWeJRSyqsnejy291Igffr00Wbz5s3TZv7+/o7vOXHiRG32j3/8Q5vNmDFDm0VERGiznJwcbbZt2zZtJiKSmpqqzV5++WVtlp2dbVwXel5WqcS4rcMmffv21Wa9evXSZt27d3d8z8uXL2uzc+fOOV7XqYoVK2qz4OBgR2v27NlTm61atcrRmqWJmzvstv6OHDlSm7366qvarFKlSo7vuXjxYm1m+vP5zJkzju+pEx0dbcwHDBigzRITE7VZZGSkNjN9fpq+ZoqILFy40JiXBm7ur4j7OmzSuXNnbbZkyRJtFhISYlx3wYIF2uzs2bPa7L333jOu68SJEyeM+alTp4r8nmPHjtVmEyZMcLzusmXLtNnDDz/seN3i5uYO+1J/napcubIxN/3Znl/3dbp166bNAgICtNknn3xiXNf092BTdujQIeO60POmv7ziCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVHuXl2ZVuO0YyPT1dmzVq1KgYd1I4mZmZ2mzu3LnabNy4cRZ2g8Jw8zGwIu7rsA0zZ8405qZjhcPCwop6O4Xi56f/d4Hz589rM9Ox8m+++aY2y87O9m5jpZibO+xL/W3RooU2+/TTT7VZpUqVjOuWL1/e6ZaKXH4fD6efSzk5Odps79692qx79+7Gdfft2+doP77Ezf0V8a0Ox8bGarO1a9dqszp16tjYjhU7duww5rt379ZmTj/Xbr31Vm0WHx/vaE0Rke+++06bNWvWzPG6xc3NHfal/gIlwZv+8oonAAAAAAAAWMHgCQAAAAAAAFYweAIAAAAAAIAVDJ4AAAAAAABgBYMnAAAAAAAAWMHgCQAAAAAAAFZ4lJdnV7rtGMkzZ85os4oVK1q55+XLl7XZyZMntdmCBQu02axZs7TZgQMHvNsYXMHNx8CKuK/DJaFJkyba7JZbbiny+/Xq1UubnTp1ynhtSkqKNjt9+rQ2S0tLy3dfyJubO1wW+hsXF2fMExISHF3bp08fbRYcHJz/xvKQk5NjzC9duuRo3enTp2uzpKQkR2uWFW7ur0jp6bCpT++++67xWlPfsrKyHO0nJCREmwUGBjpaU8T88SqJzzXT15zJkydrM1/6uuHmDpeW/gK2eNNfXvEEAAAAAAAAKxg8AQAAAAAAwAoGTwAAAAAAALCCwRMAAAAAAACsYPAEAAAAAAAAKxg8AQAAAAAAwAqP8vLsSrcdI9myZUttNmLECG3WvXt3bTZt2jTjPXfs2KHNVq5cabwWpZ+bj4EVcV+HAbdxc4fpr3ONGjXSZt26dXO05qFDh4z54sWLHa0L59zcXxE6LCISHx+vzVJSUhyt2bVrV23WpEkTR2uKiEyaNEmb2fhcmzFjhjHfunWrNps/f35Rb6dEuLnD9Bcw86a/vOIJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUe5eXZlRwjCZi5+RhYEToM5MfNHaa/gJmb+ytCh4H8uLnD9Bcw86a/vOIJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABYweAJAAAAAAAAVjB4AgAAAAAAgBUMngAAAAAAAGAFgycAAAAAAABY4VFKqZLeBAAAAAAAAEofXvEEAAAAAAAAKxg8AQAAAAAAwAoGTwAAAAAAALCCwRMAAAAAAACsYPAEAAAAAAAAKxg8AQAAAAAAwAoGTwAAAAAAALCCwRMAAAAAAACsYPAEAAAAAAAAK/4fq+g703YxiEIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(state, images):\n",
    "    logits = state.apply_fn({'params': state.params}, images)\n",
    "    return jnp.argmax(logits, axis=-1)\n",
    "\n",
    "def visualize_predictions(state, dataset, n_display=5):\n",
    "    # Get a batch of images and labels\n",
    "    batch = next(iter(dataset.batch(10).as_numpy_iterator()))\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    images, true_labels = batch\n",
    "    images = images[-1]\n",
    "    true_labels = true_labels[-1]\n",
    "    \n",
    "    # Make predictions\n",
    "    predicted_labels = predict(state, images)\n",
    "    \n",
    "    # Plot the images with true and predicted labels\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n_display):\n",
    "        plt.subplot(1, n_display, i+1)\n",
    "        plt.imshow(images[i, ..., 0], cmap='gray')\n",
    "        plt.title(f'True: {true_labels[i]}, Predicted: {predicted_labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(state, dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
